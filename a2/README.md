Main file: `main.m`
Code available: https://github.com/yAya-yns/Mobile_Robotics_and_Perception/tree/main/a2

Credit: S L Waslander

## Introduction: ##
This project will introduce you to the idea of estimating the motion of a mobile robot using wheel odometry, and then also using that wheel odometry to make a simple map.  It uses a dataset previously gathered in a mobile robot simulation environment called Gazebo. Watch the video 'gazebo.mp4' to visualize what the robot did, what its environment looks like, and what its sensor stream looks like.

There are three objectives to complete:
  - Objective 1: Implement noise-free wheel odometry algorithm
  - Objective 2: add noise to data and re-run wheel odometry algorithm
  - Objective 3: build a map from ground truth and noisy wheel odometry

## Objective 1: ##
Random points generator is applied for objective 1 taks, shown below:
![Alt text](/a2/q1.png "Noise Free Odometry vs Ground-truth")

Observation: 
- TODO


## Objective 2: ##
Random points generator is applied for objective 1 taks, shown below:
![Alt text](/a2/q2.png "Noise added path with 100 iterations")


Observation: 
- TODO


## Objective 3: ##
![Alt text](/a2/q3_no_patches.png "Map with no Patch applied")
![Alt text](/a2/q3_w_patch1.png "Map with Patch 1 applied")
![Alt text](/a2/q3_w_patch2.png "Map with Patch 2 applied")
![Alt text](/a2/q3_w_patch1and2.png "Map with both Patch applied")


Observation: 
- TODO
