Main file: `main.m`
Code available: https://github.com/yAya-yns/Mobile_Robotics_and_Perception/tree/main/a2

Credit: S L Waslander

## Introduction: ##
This project will introduce you to the idea of estimating the motion of a mobile robot using wheel odometry, and then also using that wheel odometry to make a simple map.  It uses a dataset previously gathered in a mobile robot simulation environment called Gazebo. Watch the video 'gazebo.mp4' to visualize what the robot did, what its environment looks like, and what its sensor stream looks like.

There are three objectives to complete:
  - Objective 1: Implement noise-free wheel odometry algorithm
  - Objective 2: add noise to data and re-run wheel odometry algorithm
  - Objective 3: build a map from ground truth and noisy wheel odometry

## Objective 1: ##
We implement an algorithm to estimate the pose of the robot throughout motion using the wheel odometry data (t_odom, v_odom, omega_odom) and assuming a differential-drive robot model. The estimations are saved as variables: (x_odom y_odom theta_odom) so that the comparison plots can be generated below: 
![Alt text](/a2/q1.png "Noise Free Odometry vs Ground-truth")


## Objective 2: ##
We deliberately add some noise to the linear and angular velocities to simulate what real wheel odometry is like. The same algorithm from Objective#1 is used here. However, we loops 100 times with different random noise. From picture below, we discover that the path deviate much more as iteration increase.
![Alt text](/a2/q2.png "Noise added path with 100 iterations")


## Objective 3: ##
We construct the map using laser scan along with odometry data through frame transformation. i.e. we measured the map and obtain data in robot frame, then transform them into the inertial frame based on robot's coordinate relative to the inertial frame according to the wheel odom. 

To increase the precision of the mapping, 2 patches are applied:
1. Only plot the laser scans if the angular velocity is less than 0.1 rad/s
  - because timestamp interpolation errors have more of an effect when the robot is turning quickly.
2. Account for the fact that the origin of the laser scans is about 10 cm behind the origin of the robot.

For comparison purpose, we also show maps with no patch and single patch. We found the map is crisper with both patches applied. 

### Map with no Patches applied (generated by Red: noisy-data; Blue: noise-free data)
![Alt text](/a2/q3_w_patch1and2.png "Map with both Patch applied")

### Map with no Patches applied:
![Alt text](/a2/q3_no_patches.png "Map with no Patch applied")
### Map with Patch 1 applied:
![Alt text](/a2/q3_w_patch1.png "Map with Patch 1 applied")
### Map with Patch 2 applied:
![Alt text](/a2/q3_w_patch2.png "Map with Patch 2 applied")
